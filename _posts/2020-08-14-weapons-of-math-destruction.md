---
layout: post
title: "Leído: 'Weapons of Math Destruction' de Cathy O'Neil"
author: "José Ángel Fernández"
categories: blog
tags: [libros]
image: weapons.jfif
---

La tecnología evoluciona de forma tan rápida que cada vez resulta más complicado llegar a conocer los detalles de todo lo que se encuentra por debajo de cosas cotidianas que hacemos; por ejemplo, realizar una llamada desde nuestro teléfono móvil o arrancar el coche por la mañana para ir a trabajar. Este proceso de estratificación hace que de forma general nos quedemos en la cara más visible de la tecnología *(i.e. darle a llamar en nuestro teléfono o girar la llave para arrancar el coche)* y solo si somos algo curiosos, nos adentremos en las capas inferiores para entender lo que sucede. 

Este desconocimiento, desde mi punto de vista, llega a convertirnos en vulnerables. Quedamos a merced de terceros cuando algo falla, no funciona como se espera o posiblemente peor, cuando funciona correctamente pero no somos conscientes de lo que está sucediendo por debajo. ¿Os suenan las cookies y la trazabilidad de la gente a través de internet? ¿La descarga de aplicaciones gratuitas y las "sorpresas" que muchas veces vienen dentro?. Si trabajas o estás interesado en este sector probablemente sea así, ¿pero tus familiares y amigos son conscientes?

Después de esto diréis, ¿qué tiene que ver lo anterior con este libro? Bien, la relación se encuentra en el enfoque del libro sobre uno de los aspectos de la tecnología que nos encontramos en el día a día y del que no somos conscientes del impacto que tiene en nuestra vida: los algoritmos y el Big Data. 

Para muchas personas de nuestro alrededor, la mayor interacción consciente con sistemas "inteligentes" son las preguntas que realizan a su asistente en el móvil para conocer el tiempo o las recomendaciones que recibe de Netflix, Spotify o Amazon sobre el contenido que consumir a continuación. Experiencias que en algunos casos es posible que les hagan cuestionarse hasta qué punto de verdad existe "inteligencia" en ellos, si no, ¿cómo es posible que Amazon te recomiende de nuevo el mismo producto que ya has comprado?. 

Sin embargo, existe un gran número de algoritmos, más sútiles e incluso impercetibles, que tienen un impacto mayor en nuestro día a día sin que seamos conscientes de ellos. Estos algoritmos son los que Cathy O'Neil denomina como *"weapons of math destruction"*:  una colección de modelos opacos, no controlados por ningún tipo de regulación, difíciles de corregir si se equivocan con nosotros y con una escalabilidad tan alta que afectan a un gran número de personas. 

Estos algoritmos se encuentran en muchos de nuestros escenarios cotidianos. Cathy escoge situaciones como la búsqueda de trabajo, la obtención de préstamos, la contratación de seguros médicos privados o los sistemas de la policía para prevenir la delicuencia y crímenes. Sí que es cierto que son muy particulares del mercado estadounidense, por lo que en algunos casos resulta complicado seguirlos en detalle al no conocerlos de primera mano. Aún así, es fácil seguir el hilo y entender cómo estos modelos, si no son diseñados correctamente, pueden llegar a ser armas peligrosas que condicionen el futuro de los ciudadanos desde que son prácticamente niños.

Un matiz relevante es que en los casos concretos del libro siempre salen perjudicados los mismos: aquellos pertenecientes a clases bajas, con una educación limitada y con recursos económicos reducidos. Algo normal porque al final estos modelos recogen los mismos prejuicios de las personas que los diseñaron pero camuflados con una capa de neutralidad al estar basado en un modelo matemático. Los números no mienten, ¿no?

Aunque tras acabar de leer el libro el panorama puede parecer algo desolador, sí que es cierto que existen movimientos para lograr evitar muchos de los problemas que menciona como el impuso de [*Explanable AI (xAI)*](https://es.wikipedia.org/wiki/Inteligencia_artificial_explicable) o [*Responsible AI*](https://www.microsoft.com/en-us/ai/responsible-ai). Avances que nos permitan tener esa visión tan *anti Big Data* o *anti IA* como la que puede llegar a extraerse de él.

No obstante, es una lectura interesante para ser consciente de a dónde nos puede dirigir este mundo liderado por modelos de aprendizaje automático si no se tienen en cuenta unos principios básicos de responsabilidad por parte de las personas que los crean. 
